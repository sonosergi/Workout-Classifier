{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonosergi/Workout-Classifier/blob/main/WorkOutClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MOUNT GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "_ZtXIahQbROB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5XIOh6kj9IEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac40f28-bfe2-4669-d23f-625cfd19ec18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jgBIYCLJfey"
      },
      "source": [
        "### IMPORT MODULES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TwCVRIfbKmyk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import string\n",
        "import urllib.request\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v9MFOFib93qO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from collections import deque\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.applications import InceptionResNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH0schbomL4t"
      },
      "source": [
        "### IMPORT DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOnApLCVGDtU"
      },
      "outputs": [],
      "source": [
        "# Set the file path of the downloaded zip file from Kaggle\n",
        "url = '/file path downloaded from kaggle/archive.zip'\n",
        "\n",
        "# Open the zip file using zipfile.ZipFile\n",
        "zip_ref = zipfile.ZipFile(url, \"r\")\n",
        "\n",
        "# Extract all files from the zip file to the specified directory (/tmp/Data-Keggle)\n",
        "zip_ref.extractall(\"/tmp/Data-Keggle\")\n",
        "zip_ref.close() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeLVU8rmJKNe"
      },
      "source": [
        "### HYPERPARAMETER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XbYlZL0JDf7"
      },
      "outputs": [],
      "source": [
        "height = 256\n",
        "width = 256\n",
        "channels = 3\n",
        "BATCH_SIZE = 32\n",
        "SEED = 127\n",
        "img_shape = (height, width, channels)\n",
        "IMG_SIZE = (height, width)\n",
        "CLASSES = 22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgsPX6AcJpxY"
      },
      "source": [
        "### PROCESS DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7meDLOAyuy1"
      },
      "outputs": [],
      "source": [
        "# Set the path to the directory where the dataset is stored\n",
        "DATA_DIR = '/tmp/Data-Keggle'\n",
        "\n",
        "# Split the dataset into training (80%) and validation (20%) sets using Keras' image_dataset_from_directory function\n",
        "# The labels are inferred from the directory structure\n",
        "# The images are resized to IMG_SIZE\n",
        "# The data is shuffled and divided into batches of size BATCH_SIZE\n",
        "# A random seed is set for reproducibility\n",
        "training_data = tf.keras.utils.image_dataset_from_directory(DATA_DIR,\n",
        "  labels = 'inferred',\n",
        "  label_mode = 'categorical',\n",
        "  validation_split = 0.3,\n",
        "  subset = 'training',\n",
        "  image_size = IMG_SIZE,\n",
        "  shuffle = True,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  seed = 127\n",
        ")\n",
        "\n",
        "# Create the validation dataset using the same settings as the training dataset, but with a different subset parameter\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(DATA_DIR,\n",
        "  labels = 'inferred',\n",
        "  label_mode = 'categorical',\n",
        "  validation_split = 0.3,\n",
        "  subset = 'validation',\n",
        "  image_size = IMG_SIZE,\n",
        "  shuffle = True,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  seed = 127\n",
        ")\n",
        "\n",
        "# Save the class names to a file for later reference\n",
        "labels = training_data.class_names\n",
        "print(labels)\n",
        "\n",
        "with open('workout_label.txt', 'w') as f:\n",
        "    for workout_class in labels:\n",
        "        f.write(f'{workout_class}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7OzgJESqrcj"
      },
      "outputs": [],
      "source": [
        "#training_data = ImageDataGenerator(rescale = 1/255)\n",
        "#test_data = ImageDataGenerator(rescale = 1/255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g94cEh7-X1Zl"
      },
      "source": [
        "### DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW3Opf1eX0n-"
      },
      "outputs": [],
      "source": [
        "# Define a data augmentation pipeline using the Keras Sequential API\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal\"),   # randomly flip images horizontally\n",
        "  tf.keras.layers.RandomRotation(0.2),        # randomly rotate images up to 20%\n",
        "  tf.keras.layers.RandomZoom(0.2),            # randomly zoom images up to 20%\n",
        "  tf.keras.layers.RandomContrast(0.2),        # randomly adjust contrast up to 20%\n",
        "  tf.keras.layers.GaussianNoise(0.2),         # add random Gaussian noise to images with a standard deviation of 0.2\n",
        "  tf.keras.layers.RandomBrightness(0.2)       # randomly adjust brightness up to 20%\n",
        "])\n",
        "\n",
        "# Apply the data augmentation pipeline to the training data using the map() method\n",
        "training_data = training_data.map(lambda x, y: (data_augmentation(x, training=True), y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA VISUALIZATION"
      ],
      "metadata": {
        "id": "9-e_1SWtYx9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeIj30LcTq4X"
      },
      "outputs": [],
      "source": [
        "# Define a function to display images from a TensorFlow dataset\n",
        "def show_img(data):\n",
        "    # Set the size of the figure\n",
        "    plt.figure(figsize=(10,10))\n",
        "    # Take the first batch of images and labels from the dataset\n",
        "    for images, labels in data.take(1):\n",
        "        # Loop through the first 9 images in the batch\n",
        "        for i in range(9):\n",
        "            # Create a subplot for each image\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            # Display the image as a numpy array with uint8 data type\n",
        "            ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            # Turn off the axis labels for the subplot\n",
        "            ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaU4zWZpWqRJ"
      },
      "outputs": [],
      "source": [
        "show_img(training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i24fov8z9sNG"
      },
      "source": [
        "### MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfeifktnpHs_"
      },
      "outputs": [],
      "source": [
        "# Import the InceptionResNetV2 pre-trained model from Keras with weights pre-trained on ImageNet\n",
        "pre_trained_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=img_shape, pooling='avg')\n",
        "\n",
        "# Set all layers in the pre-trained model to non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Print a summary of the pre-trained model\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg67lUbsTiXS"
      },
      "source": [
        "\n",
        "### FREEZE THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVtW6-FxsOtg"
      },
      "outputs": [],
      "source": [
        "# Set the output of the pre-trained model as the input for the new layers\n",
        "x = pre_trained_model.output\n",
        "\n",
        "# Add a batch normalization layer to normalize the input to the next layer\n",
        "x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
        "\n",
        "# Add a dropout layer to randomly drop out 20% of the input units\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "# Add a fully connected layer with 1024 units and ReLU activation function\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add a fully connected layer with 512 units and ReLU activation function\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a fully connected layer with 256 units and ReLU activation function\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "# Add a dropout layer to randomly drop out 20% of the input units\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "# Add a fully connected layer with the number of units equal to the number of labels and softmax activation function\n",
        "predictions = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "# Create a new Keras model with the pre-trained model's input as the input and the new layers as the output\n",
        "iTrainer = tf.keras.models.Model(inputs=pre_trained_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with Adam optimizer, categorical cross-entropy loss, and accuracy metric\n",
        "iTrainer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model's architecture and parameters\n",
        "iTrainer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trVLHHmfnU6s"
      },
      "source": [
        "### TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks to save the best model and stop training early if accuracy stops improving\n",
        "checkpoint_callback = ModelCheckpoint('/your/path/best_model.h5',\n",
        "                                       monitor='val_accuracy',\n",
        "                                       verbose=1,\n",
        "                                       save_best_only=True,\n",
        "                                       mode='max')\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='accuracy',\n",
        "                                        patience=5,\n",
        "                                        mode='auto',\n",
        "                                        restore_best_weights=True)\n",
        "\n",
        "# Train the model with the defined callbacks\n",
        "history = iTrainer.fit(training_data,\n",
        "                       validation_data=test_data,\n",
        "                       epochs=200,\n",
        "                       callbacks=[early_stopping_callback, checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "k7L-4EkzA8Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONVERT THE .h5 FILE TO .json"
      ],
      "metadata": {
        "id": "ghFCy7RcdpeD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxGbvN5d24vf"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqt2mhkG256e"
      },
      "outputs": [],
      "source": [
        "!tensorflowjs_converter --input_format=keras /your/path/best_model.h5 /your/path"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO49kS7c6GaQilRT8GZ5Tx5",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}